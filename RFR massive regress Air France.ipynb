{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regression of Air France Revenue:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from colorspacious import cspace_converter\n",
    "from collections import OrderedDict\n",
    "from matplotlib import cm\n",
    "# Hierarchical CLustering of OECD Composite Indicator\n",
    "# Import normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import kurtosis, skew\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import pdb\n",
    "mpl.rcParams['figure.figsize'] = 20, 5\n",
    "mpl.rcParams['lines.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SALES_REV_TURN</th>\n",
       "      <th>FUEL_EXPENSES</th>\n",
       "      <th>IS_OPERATING_EXPN</th>\n",
       "      <th>IS_SELLING_EXPENSES</th>\n",
       "      <th>CF_DEPR_AMORT</th>\n",
       "      <th>ACCT_RCV_TURN</th>\n",
       "      <th>BS_ACCT_PAYABLE</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>IS_INT_EXPENSE</th>\n",
       "      <th>BS_TOTAL_CAPITAL_LEASES</th>\n",
       "      <th>...</th>\n",
       "      <th>Maintenance</th>\n",
       "      <th>EBITDAR.2</th>\n",
       "      <th>Transavia.2</th>\n",
       "      <th>EBITDAR.3</th>\n",
       "      <th>Other</th>\n",
       "      <th>EBITDAR.4</th>\n",
       "      <th>Cargo</th>\n",
       "      <th>EBITDAR.5</th>\n",
       "      <th>Adjustments.1</th>\n",
       "      <th>Revenue.7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-06-30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-09-30</th>\n",
       "      <td>-0.023831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-31</th>\n",
       "      <td>-0.030902</td>\n",
       "      <td>0.934844</td>\n",
       "      <td>0.969372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.082305</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.039942</td>\n",
       "      <td>-0.087838</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-03-31</th>\n",
       "      <td>-0.043367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-06-30</th>\n",
       "      <td>0.003000</td>\n",
       "      <td>-0.515373</td>\n",
       "      <td>-0.515472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.399209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074182</td>\n",
       "      <td>-1.096296</td>\n",
       "      <td>-0.597701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>0.141061</td>\n",
       "      <td>0.115928</td>\n",
       "      <td>0.048401</td>\n",
       "      <td>0.198276</td>\n",
       "      <td>-0.048714</td>\n",
       "      <td>-0.041469</td>\n",
       "      <td>0.049423</td>\n",
       "      <td>-3.212121</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>-0.252509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>0.138868</td>\n",
       "      <td>0.163007</td>\n",
       "      <td>0.031949</td>\n",
       "      <td>-0.043165</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>-0.020812</td>\n",
       "      <td>0.024333</td>\n",
       "      <td>1.972603</td>\n",
       "      <td>-0.032787</td>\n",
       "      <td>0.287325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>-0.133466</td>\n",
       "      <td>-0.029775</td>\n",
       "      <td>0.006811</td>\n",
       "      <td>-0.030075</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.138578</td>\n",
       "      <td>-0.057471</td>\n",
       "      <td>-0.968664</td>\n",
       "      <td>-0.059322</td>\n",
       "      <td>-0.260117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>-0.084429</td>\n",
       "      <td>-0.101048</td>\n",
       "      <td>-0.035824</td>\n",
       "      <td>-0.031008</td>\n",
       "      <td>-0.012228</td>\n",
       "      <td>-0.130729</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>-9.382353</td>\n",
       "      <td>-0.045045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-30</th>\n",
       "      <td>0.177748</td>\n",
       "      <td>0.169026</td>\n",
       "      <td>0.064424</td>\n",
       "      <td>0.068000</td>\n",
       "      <td>0.028886</td>\n",
       "      <td>-0.021711</td>\n",
       "      <td>0.015022</td>\n",
       "      <td>-2.315789</td>\n",
       "      <td>0.084906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows Ã— 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SALES_REV_TURN  FUEL_EXPENSES  IS_OPERATING_EXPN  \\\n",
       "dates                                                          \n",
       "2002-06-30        0.000000       0.000000           0.000000   \n",
       "2002-09-30       -0.023831       0.000000           0.000000   \n",
       "2002-12-31       -0.030902       0.934844           0.969372   \n",
       "2003-03-31       -0.043367       0.000000           0.000000   \n",
       "2003-06-30        0.003000      -0.515373          -0.515472   \n",
       "...                    ...            ...                ...   \n",
       "2018-06-30        0.141061       0.115928           0.048401   \n",
       "2018-09-30        0.138868       0.163007           0.031949   \n",
       "2018-12-31       -0.133466      -0.029775           0.006811   \n",
       "2019-03-31       -0.084429      -0.101048          -0.035824   \n",
       "2019-06-30        0.177748       0.169026           0.064424   \n",
       "\n",
       "            IS_SELLING_EXPENSES  CF_DEPR_AMORT  ACCT_RCV_TURN  \\\n",
       "dates                                                           \n",
       "2002-06-30             0.000000       0.000000       0.000000   \n",
       "2002-09-30             0.000000       0.000000       0.000000   \n",
       "2002-12-31             0.000000       1.082305       0.000000   \n",
       "2003-03-31             0.000000       0.000000       0.000000   \n",
       "2003-06-30             0.000000      -0.399209       0.000000   \n",
       "...                         ...            ...            ...   \n",
       "2018-06-30             0.198276      -0.048714      -0.041469   \n",
       "2018-09-30            -0.043165       0.005690      -0.020812   \n",
       "2018-12-31            -0.030075       0.041018       0.138578   \n",
       "2019-03-31            -0.031008      -0.012228      -0.130729   \n",
       "2019-06-30             0.068000       0.028886      -0.021711   \n",
       "\n",
       "            BS_ACCT_PAYABLE      EBIT  IS_INT_EXPENSE  \\\n",
       "dates                                                   \n",
       "2002-06-30         0.000000  0.000000        0.000000   \n",
       "2002-09-30         0.000000  0.000000        0.000000   \n",
       "2002-12-31        -0.039942 -0.087838        0.740000   \n",
       "2003-03-31         0.040091  0.000000        0.000000   \n",
       "2003-06-30        -0.074182 -1.096296       -0.597701   \n",
       "...                     ...       ...             ...   \n",
       "2018-06-30         0.049423 -3.212121        0.070175   \n",
       "2018-09-30         0.024333  1.972603       -0.032787   \n",
       "2018-12-31        -0.057471 -0.968664       -0.059322   \n",
       "2019-03-31         0.001220 -9.382353       -0.045045   \n",
       "2019-06-30         0.015022 -2.315789        0.084906   \n",
       "\n",
       "            BS_TOTAL_CAPITAL_LEASES  ...  Maintenance    EBITDAR.2  \\\n",
       "dates                                ...                             \n",
       "2002-06-30                 0.000000  ...          0.0          0.0   \n",
       "2002-09-30                 0.000000  ...          0.0          0.0   \n",
       "2002-12-31                 0.000000  ...          0.0          0.0   \n",
       "2003-03-31                 0.000000  ...          0.0          0.0   \n",
       "2003-06-30                 0.000000  ...          0.0          0.0   \n",
       "...                             ...  ...          ...          ...   \n",
       "2018-06-30                -0.252509  ...          0.0          0.0   \n",
       "2018-09-30                 0.287325  ...          0.0          0.0   \n",
       "2018-12-31                -0.260117  ...          0.0          0.0   \n",
       "2019-03-31                 0.000000  ...          0.0          0.0   \n",
       "2019-06-30                 0.000000  ...          0.0          0.0   \n",
       "\n",
       "            Transavia.2    EBITDAR.3  Other    EBITDAR.4  Cargo    EBITDAR.5  \\\n",
       "dates                                                                          \n",
       "2002-06-30          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2002-09-30          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2002-12-31          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2003-03-31          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2003-06-30          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "...                 ...          ...    ...          ...    ...          ...   \n",
       "2018-06-30          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2018-09-30          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2018-12-31          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2019-03-31          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "2019-06-30          0.0          0.0    0.0          0.0    0.0          0.0   \n",
       "\n",
       "            Adjustments.1    Revenue.7  \n",
       "dates                                   \n",
       "2002-06-30            0.0          0.0  \n",
       "2002-09-30            0.0          0.0  \n",
       "2002-12-31            0.0          0.0  \n",
       "2003-03-31            0.0          0.0  \n",
       "2003-06-30            0.0          0.0  \n",
       "...                   ...          ...  \n",
       "2018-06-30            0.0          0.0  \n",
       "2018-09-30            0.0          0.0  \n",
       "2018-12-31            0.0          0.0  \n",
       "2019-03-31            0.0          0.0  \n",
       "2019-06-30            0.0          0.0  \n",
       "\n",
       "[69 rows x 360 columns]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = 20, 5\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "df = pd.read_csv('regressmass.csv', parse_dates=['dates'], index_col='dates')\n",
    "# df = df[df.applymap(np.isreal).any(1)]\n",
    "df = df.interpolate().ffill().bfill().dropna()\n",
    "df = df.select_dtypes(include=['float64', 'int64'])\n",
    "# df= df.replace([np.inf, -np.inf], np.nan)\n",
    "# df = df_model = df\n",
    "df.pct_change().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_names = ['SALES_REV_TURN']\n",
    "\n",
    "# df_model = df_model.drop(columns='Adj Close')\n",
    "features_names_model = df_model.columns.drop(y_names).tolist()      \n",
    "\n",
    "feature_target_df = df_model[y_names + features_names_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification of features/target data properties (diff, shift, lag, etc..).\n",
    "targets = feature_target_df[y_names]\n",
    "features = feature_target_df[features_names_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLaggedFeatures(s,lag=2,dropna=True):\n",
    "    '''\n",
    "    Builds a new DataFrame to facilitate regressing over all possible lagged features\n",
    "    '''\n",
    "    if type(s) is pd.DataFrame:\n",
    "        new_dict={}\n",
    "        for col_name in s:\n",
    "            new_dict[col_name]=s[col_name]\n",
    "            # create lagged Series\n",
    "            for l in range(1,lag+1):\n",
    "                new_dict['%s_lag%d' %(col_name,l)]=s[col_name].shift(l)\n",
    "        res=pd.DataFrame(new_dict,index=s.index)\n",
    "\n",
    "    elif type(s) is pd.Series:\n",
    "        the_range=range(lag+1)\n",
    "        res=pd.concat([s.shift(i) for i in the_range],axis=1)\n",
    "        res.columns=['lag_%d' %i for i in the_range]\n",
    "    else:\n",
    "        print ('Only works for DataFrame or Series')\n",
    "        return None\n",
    "    if dropna:\n",
    "        return res.dropna()\n",
    "    else:\n",
    "        return res\n",
    "\n",
    "features_lagged = buildLaggedFeatures(features, lag=10, dropna=True)\n",
    "features = features_lagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dates\n",
       "2004-12-31    8409\n",
       "2005-03-31    3948\n",
       "2005-06-30    6710\n",
       "2005-09-30    3269\n",
       "2005-12-31    4631\n",
       "Name: RANDOM, dtype: int32"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['RANDOM'] = np.random.randint(3000,10000, features.shape[0])\n",
    "features['RANDOM'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test-Train split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69, 359) (41, 359) (28, 359)\n"
     ]
    }
   ],
   "source": [
    "# Import the statsmodels.api library with the alias sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to the features\n",
    "linear_features = sm.add_constant(features)\n",
    "\n",
    "# Create a size for the training set that is 85% of the total number of samples\n",
    "train_size = int(0.60 * features.shape[0])\n",
    "train_features = X = linear_features[:train_size]\n",
    "train_targets  = Y = targets[:train_size]\n",
    "test_features  = x = linear_features[train_size:]\n",
    "test_targets   = y = targets[train_size:]\n",
    "\n",
    "print(linear_features.shape, train_features.shape, test_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regression using Random Forest Regressor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9251176170346833\n",
      "0.06415949728334525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfr = RandomForestRegressor(n_estimators=400)\n",
    "rfr.fit(train_features, train_targets)\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(rfr.score(X, Y))\n",
    "print(rfr.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with classic Random Forest Regressor we can extract features importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exrtract features importance with built-in function of random forest regressor\n",
    "features_importances = rfr.feature_importances_\n",
    "\n",
    "# Sort the index that will be our reference for the positino of each index regarding there importances\n",
    "sorted_index = np.argsort(features_importances)[::-1][:100]\n",
    "\n",
    "# Create the corresponding labels to importances position\n",
    "features_count = range(len(sorted_index))\n",
    "labels = np.array(linear_features.columns.to_list())[sorted_index]\n",
    "\n",
    "def map_importance(model):\n",
    "   \n",
    "    # Plot the graph\n",
    "    plt.bar(features_count, features_importances[sorted_index], tick_label=labels)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 20 , 5\n",
    "map_importance(rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X = features[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:185: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropping 'Revenue_lag7' at index: 0\n",
      "dropping 'Sales per Employee_lag7' at index: 0\n",
      "dropping '    + (Income) Loss from Affiliates' at index: 0\n",
      "dropping 'YIELD_PER_PASS_MILES_KM_lag10' at index: 0\n",
      "dropping '  + Other ST Liabilities_lag2' at index: 0\n",
      "dropping 'BS_INVENTORIES_lag2' at index: 0\n",
      "dropping 'TOTAL_EQUITY_lag10' at index: 0\n",
      "dropping '  + Inventories' at index: 0\n",
      "dropping '    + Acq of Fixed & Intang_lag7' at index: 0\n",
      "dropping '  + Cash From (Repayment) Debt_lag9' at index: 0\n",
      "dropping '  + Other LT Assets_lag1' at index: 0\n",
      "dropping '  + Payables & Accruals' at index: 0\n",
      "dropping '    + Misc LT Assets_lag2' at index: 0\n",
      "dropping 'BS_TOT_NON_CUR_ASSET_lag2' at index: 0\n",
      "dropping '  - Operating Expenses_lag7' at index: 0\n",
      "dropping 'FUEL_EXPENSES_lag5' at index: 0\n",
      "dropping 'FUEL_EXPENSES_lag10' at index: 0\n",
      "dropping '    + Deferred Tax Liabilities_lag9' at index: 0\n",
      "dropping 'BS_TOT_NON_CUR_ASSET_lag3' at index: 0\n",
      "dropping '    + Other Intangible Assets_lag5' at index: 0\n",
      "dropping 'Total Liabilities & Equity_lag1' at index: 0\n",
      "dropping 'Diluted Weighted Avg Shares_lag6' at index: 0\n",
      "dropping 'BS_TOT_ASSET_lag2' at index: 0\n",
      "dropping 'Personnel Expenses_lag7' at index: 0\n",
      "dropping 'Basic Weighted Avg Shares_lag7' at index: 0\n",
      "dropping '    + Other Inventory' at index: 0\n",
      "dropping 'Total Noncurrent Assets_lag1' at index: 0\n",
      "dropping '  + Other LT Assets_lag8' at index: 0\n",
      "dropping 'Total Assets_lag8' at index: 0\n",
      "dropping 'Total Liabilities & Equity' at index: 0\n",
      "dropping 'FUEL_EXPENSES_lag2' at index: 0\n",
      "dropping 'Total Liabilities & Equity_lag5' at index: 0\n",
      "dropping '    + Other Inventory_lag1' at index: 0\n",
      "dropping 'LOAD_FACTOR_lag10' at index: 0\n",
      "dropping '  - Treasury Stock_lag1' at index: 0\n",
      "dropping 'Total Liabilities & Equity_lag2' at index: 0\n",
      "dropping 'Total Current Liabilities_lag10' at index: 0\n",
      "dropping '  + Other LT Liabilities_lag5' at index: 0\n",
      "dropping '  Assets.1_lag6' at index: 0\n",
      "dropping 'Total Assets_lag1' at index: 0\n",
      "dropping 'BS_CUR_LIAB_lag2' at index: 0\n",
      "dropping '    + Raw Materials_lag4' at index: 6\n",
      "dropping '    + Raw Materials_lag1' at index: 32\n",
      "dropping 'BS_TOT_NON_CUR_ASSET' at index: 7\n",
      "dropping 'EBITA_lag10' at index: 12\n",
      "dropping 'BS_TOT_LIAB2_lag3' at index: 3\n",
      "dropping '    + Accounts Payable_lag10' at index: 51\n",
      "dropping 'Total Assets' at index: 15\n",
      "dropping '    + Property, Plant & Equip_lag1' at index: 26\n",
      "dropping '    + Other Inventory_lag6' at index: 32\n",
      "dropping 'Capital Leases - Total_lag1' at index: 6\n",
      "dropping '    + Accounts Payable_lag5' at index: 31\n",
      "dropping 'BS_TOT_LIAB2' at index: 18\n",
      "dropping 'Diluted Weighted Avg Shares_lag9' at index: 32\n",
      "dropping '    + Raw Materials' at index: 14\n",
      "dropping 'BS_ACCT_PAYABLE_lag7' at index: 40\n",
      "dropping 'BS_ACCT_PAYABLE_lag9' at index: 40\n",
      "dropping 'Total Assets_lag3' at index: 25\n",
      "dropping '  + Other ST Liabilities_lag8' at index: 6\n",
      "dropping 'BS_TOT_LIAB2_lag4' at index: 16\n",
      "dropping 'NON_CUR_LIAB_lag10' at index: 17\n",
      "dropping 'Total Current Liabilities_lag4' at index: 18\n",
      "dropping '  Revenue_lag10' at index: 32\n",
      "dropping '  + Payables & Accruals_lag5' at index: 15\n",
      "dropping 'Future Minimum Operating Lease Obligations_lag8' at index: 11\n",
      "dropping 'FUEL_EXPENSES_lag1' at index: 34\n",
      "dropping '  + Cash, Cash Equivalents & STI_lag8' at index: 13\n",
      "dropping 'BS_CUR_ASSET_REPORT_lag9' at index: 4\n",
      "dropping '  - Operating Expenses_lag2' at index: 25\n",
      "dropping 'Basic Weighted Avg Shares' at index: 5\n",
      "dropping 'VGK US Equity' at index: 28\n",
      "dropping 'FUEL_EXPENSES_lag8' at index: 5\n",
      "dropping '  + Cash, Cash Equivalents & STI_lag1' at index: 9\n",
      "dropping 'Total Current Assets_lag10' at index: 11\n",
      "Remaining variables:\n",
      "Index(['    + Goodwill_lag6', 'IS_INT_EXPENSE_lag7', 'IS_OPERATING_EXPN_lag10',\n",
      "       '    + ST Borrowings_lag1', 'Equity Before Minority Interest_lag8',\n",
      "       '  + LT Investments & Receivables_lag8',\n",
      "       '    + ST Lease Liabilities_lag4', '  + Other LT Liabilities_lag8',\n",
      "       'Basic Weighted Avg Shares_lag5', '    + Work In Process_lag7',\n",
      "       'Pension Obligations_lag9',\n",
      "       '  + Minority/Non Controlling Interest_lag10',\n",
      "       '    + ST Finance Leases_lag4', 'Pension Obligations_lag6',\n",
      "       'Pension Obligations_lag10', 'Basic EPS from Cont Ops, Adjusted_lag2',\n",
      "       'Pension Obligations_lag8', '    + Investments in Affiliates_lag2',\n",
      "       '    + Deferred Tax Liabilities_lag4', '  + Other ST Assets_lag9',\n",
      "       'Diluted Weighted Avg Shares_lag1', '    + Misc ST Liabilities_lag8',\n",
      "       '    + ST Borrowings', '    + ST Borrowings_lag3',\n",
      "       '    + ST Borrowings_lag2',\n",
      "       'Future Minimum Operating Lease Obligations_lag7'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+ Goodwill_lag6</th>\n",
       "      <th>IS_INT_EXPENSE_lag7</th>\n",
       "      <th>IS_OPERATING_EXPN_lag10</th>\n",
       "      <th>+ ST Borrowings_lag1</th>\n",
       "      <th>Equity Before Minority Interest_lag8</th>\n",
       "      <th>+ LT Investments &amp; Receivables_lag8</th>\n",
       "      <th>+ ST Lease Liabilities_lag4</th>\n",
       "      <th>+ Other LT Liabilities_lag8</th>\n",
       "      <th>Basic Weighted Avg Shares_lag5</th>\n",
       "      <th>+ Work In Process_lag7</th>\n",
       "      <th>...</th>\n",
       "      <th>Pension Obligations_lag8</th>\n",
       "      <th>+ Investments in Affiliates_lag2</th>\n",
       "      <th>+ Deferred Tax Liabilities_lag4</th>\n",
       "      <th>+ Other ST Assets_lag9</th>\n",
       "      <th>Diluted Weighted Avg Shares_lag1</th>\n",
       "      <th>+ Misc ST Liabilities_lag8</th>\n",
       "      <th>+ ST Borrowings</th>\n",
       "      <th>+ ST Borrowings_lag3</th>\n",
       "      <th>+ ST Borrowings_lag2</th>\n",
       "      <th>Future Minimum Operating Lease Obligations_lag7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dates</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>115.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>4112.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>949.0</td>\n",
       "      <td>216.41100</td>\n",
       "      <td>52.00</td>\n",
       "      <td>...</td>\n",
       "      <td>581.00</td>\n",
       "      <td>546.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>728.0</td>\n",
       "      <td>256.834000</td>\n",
       "      <td>2373.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>2359.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>112.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3167.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>4114.5</td>\n",
       "      <td>240.5</td>\n",
       "      <td>444.00</td>\n",
       "      <td>956.0</td>\n",
       "      <td>214.75700</td>\n",
       "      <td>52.00</td>\n",
       "      <td>...</td>\n",
       "      <td>581.00</td>\n",
       "      <td>336.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>728.0</td>\n",
       "      <td>216.951700</td>\n",
       "      <td>2151.5</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>2359.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>107.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>4117.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>963.0</td>\n",
       "      <td>215.83325</td>\n",
       "      <td>52.00</td>\n",
       "      <td>...</td>\n",
       "      <td>581.00</td>\n",
       "      <td>443.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>696.0</td>\n",
       "      <td>259.450000</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>2359.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>97.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>6237.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>3994.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>216.90950</td>\n",
       "      <td>39.75</td>\n",
       "      <td>...</td>\n",
       "      <td>581.00</td>\n",
       "      <td>550.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>664.0</td>\n",
       "      <td>287.346700</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>2341.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-12-31</th>\n",
       "      <td>87.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3022.0</td>\n",
       "      <td>862.00</td>\n",
       "      <td>3992.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>256.83400</td>\n",
       "      <td>27.50</td>\n",
       "      <td>...</td>\n",
       "      <td>594.75</td>\n",
       "      <td>546.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>703.0</td>\n",
       "      <td>274.823350</td>\n",
       "      <td>2241.0</td>\n",
       "      <td>796.25</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>2323.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-03-31</th>\n",
       "      <td>95.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>796.25</td>\n",
       "      <td>4575.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>1825.0</td>\n",
       "      <td>216.95170</td>\n",
       "      <td>15.25</td>\n",
       "      <td>...</td>\n",
       "      <td>608.50</td>\n",
       "      <td>577.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>748.0</td>\n",
       "      <td>262.300000</td>\n",
       "      <td>2815.5</td>\n",
       "      <td>730.50</td>\n",
       "      <td>862.00</td>\n",
       "      <td>862.00</td>\n",
       "      <td>2305.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-06-30</th>\n",
       "      <td>93.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7804.0</td>\n",
       "      <td>730.50</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>259.45000</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>622.25</td>\n",
       "      <td>584.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>1229.5</td>\n",
       "      <td>260.460000</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>664.75</td>\n",
       "      <td>862.00</td>\n",
       "      <td>796.25</td>\n",
       "      <td>2287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-30</th>\n",
       "      <td>91.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>664.75</td>\n",
       "      <td>4062.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>444.00</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>250.33000</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>636.00</td>\n",
       "      <td>192.0</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>282.261433</td>\n",
       "      <td>2229.0</td>\n",
       "      <td>599.00</td>\n",
       "      <td>796.25</td>\n",
       "      <td>730.50</td>\n",
       "      <td>2733.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-31</th>\n",
       "      <td>87.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4271.0</td>\n",
       "      <td>599.00</td>\n",
       "      <td>4565.0</td>\n",
       "      <td>289.5</td>\n",
       "      <td>523.75</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>260.00000</td>\n",
       "      <td>29.00</td>\n",
       "      <td>...</td>\n",
       "      <td>721.00</td>\n",
       "      <td>196.0</td>\n",
       "      <td>559.000000</td>\n",
       "      <td>595.0</td>\n",
       "      <td>304.062867</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>592.75</td>\n",
       "      <td>730.50</td>\n",
       "      <td>664.75</td>\n",
       "      <td>3179.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-31</th>\n",
       "      <td>205.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4755.0</td>\n",
       "      <td>592.75</td>\n",
       "      <td>5068.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>603.50</td>\n",
       "      <td>2225.0</td>\n",
       "      <td>262.30000</td>\n",
       "      <td>42.00</td>\n",
       "      <td>...</td>\n",
       "      <td>806.00</td>\n",
       "      <td>204.0</td>\n",
       "      <td>652.333333</td>\n",
       "      <td>1327.5</td>\n",
       "      <td>325.864300</td>\n",
       "      <td>3863.0</td>\n",
       "      <td>586.50</td>\n",
       "      <td>664.75</td>\n",
       "      <td>599.00</td>\n",
       "      <td>3558.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-06-30</th>\n",
       "      <td>105.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4268.0</td>\n",
       "      <td>586.50</td>\n",
       "      <td>5158.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>683.25</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>260.46000</td>\n",
       "      <td>55.00</td>\n",
       "      <td>...</td>\n",
       "      <td>881.75</td>\n",
       "      <td>194.0</td>\n",
       "      <td>745.666667</td>\n",
       "      <td>2060.0</td>\n",
       "      <td>314.394533</td>\n",
       "      <td>3390.0</td>\n",
       "      <td>580.25</td>\n",
       "      <td>599.00</td>\n",
       "      <td>592.75</td>\n",
       "      <td>3938.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-30</th>\n",
       "      <td>218.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4646.0</td>\n",
       "      <td>580.25</td>\n",
       "      <td>5909.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>763.00</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>264.86000</td>\n",
       "      <td>41.75</td>\n",
       "      <td>...</td>\n",
       "      <td>957.50</td>\n",
       "      <td>217.0</td>\n",
       "      <td>839.000000</td>\n",
       "      <td>1711.0</td>\n",
       "      <td>302.924767</td>\n",
       "      <td>3768.0</td>\n",
       "      <td>574.00</td>\n",
       "      <td>592.75</td>\n",
       "      <td>586.50</td>\n",
       "      <td>3949.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-12-31</th>\n",
       "      <td>218.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4958.0</td>\n",
       "      <td>574.00</td>\n",
       "      <td>6008.0</td>\n",
       "      <td>3729.0</td>\n",
       "      <td>736.50</td>\n",
       "      <td>3882.0</td>\n",
       "      <td>262.60000</td>\n",
       "      <td>28.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1033.25</td>\n",
       "      <td>244.0</td>\n",
       "      <td>852.000000</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>291.455000</td>\n",
       "      <td>4679.0</td>\n",
       "      <td>568.75</td>\n",
       "      <td>586.50</td>\n",
       "      <td>580.25</td>\n",
       "      <td>3960.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>208.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>5109.0</td>\n",
       "      <td>568.75</td>\n",
       "      <td>6910.0</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>710.00</td>\n",
       "      <td>3409.0</td>\n",
       "      <td>265.80000</td>\n",
       "      <td>15.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1109.00</td>\n",
       "      <td>228.0</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>296.183400</td>\n",
       "      <td>4240.0</td>\n",
       "      <td>563.50</td>\n",
       "      <td>580.25</td>\n",
       "      <td>574.00</td>\n",
       "      <td>3971.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-06-30</th>\n",
       "      <td>206.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5239.0</td>\n",
       "      <td>563.50</td>\n",
       "      <td>6568.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>683.50</td>\n",
       "      <td>3183.0</td>\n",
       "      <td>265.23300</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1184.75</td>\n",
       "      <td>189.0</td>\n",
       "      <td>878.000000</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>309.701500</td>\n",
       "      <td>4059.0</td>\n",
       "      <td>558.25</td>\n",
       "      <td>574.00</td>\n",
       "      <td>568.75</td>\n",
       "      <td>3983.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-09-30</th>\n",
       "      <td>204.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>5201.0</td>\n",
       "      <td>558.25</td>\n",
       "      <td>7734.0</td>\n",
       "      <td>1182.0</td>\n",
       "      <td>657.00</td>\n",
       "      <td>2709.0</td>\n",
       "      <td>265.45270</td>\n",
       "      <td>2.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1260.50</td>\n",
       "      <td>177.0</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>307.950000</td>\n",
       "      <td>4690.0</td>\n",
       "      <td>553.00</td>\n",
       "      <td>568.75</td>\n",
       "      <td>563.50</td>\n",
       "      <td>3995.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-12-31</th>\n",
       "      <td>204.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>5391.0</td>\n",
       "      <td>553.00</td>\n",
       "      <td>8106.0</td>\n",
       "      <td>1179.0</td>\n",
       "      <td>623.75</td>\n",
       "      <td>3122.0</td>\n",
       "      <td>265.86500</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1336.25</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1097.000000</td>\n",
       "      <td>2689.0</td>\n",
       "      <td>302.174000</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>204.00</td>\n",
       "      <td>563.50</td>\n",
       "      <td>558.25</td>\n",
       "      <td>4007.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-31</th>\n",
       "      <td>204.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>5563.0</td>\n",
       "      <td>204.00</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>1101.0</td>\n",
       "      <td>590.50</td>\n",
       "      <td>3048.0</td>\n",
       "      <td>267.51000</td>\n",
       "      <td>3.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1412.00</td>\n",
       "      <td>177.0</td>\n",
       "      <td>1203.333333</td>\n",
       "      <td>3165.0</td>\n",
       "      <td>322.614500</td>\n",
       "      <td>4653.0</td>\n",
       "      <td>210.00</td>\n",
       "      <td>558.25</td>\n",
       "      <td>553.00</td>\n",
       "      <td>4019.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-30</th>\n",
       "      <td>204.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5499.0</td>\n",
       "      <td>210.00</td>\n",
       "      <td>7937.0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>557.25</td>\n",
       "      <td>2717.0</td>\n",
       "      <td>278.52350</td>\n",
       "      <td>4.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1403.00</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1309.666667</td>\n",
       "      <td>2503.0</td>\n",
       "      <td>311.111000</td>\n",
       "      <td>4584.0</td>\n",
       "      <td>207.00</td>\n",
       "      <td>553.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>4031.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-09-30</th>\n",
       "      <td>211.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5380.0</td>\n",
       "      <td>207.00</td>\n",
       "      <td>8299.0</td>\n",
       "      <td>1095.0</td>\n",
       "      <td>524.00</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>278.78780</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>990.00</td>\n",
       "      <td>197.0</td>\n",
       "      <td>1416.000000</td>\n",
       "      <td>1789.0</td>\n",
       "      <td>311.111000</td>\n",
       "      <td>4798.0</td>\n",
       "      <td>362.00</td>\n",
       "      <td>204.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>3380.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-12-31</th>\n",
       "      <td>211.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>5652.0</td>\n",
       "      <td>362.00</td>\n",
       "      <td>8880.0</td>\n",
       "      <td>1085.0</td>\n",
       "      <td>521.00</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>289.58300</td>\n",
       "      <td>4.50</td>\n",
       "      <td>...</td>\n",
       "      <td>897.50</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2913.000000</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>5236.0</td>\n",
       "      <td>116.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>207.00</td>\n",
       "      <td>2729.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-31</th>\n",
       "      <td>377.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5764.0</td>\n",
       "      <td>116.00</td>\n",
       "      <td>9470.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>518.00</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>293.72530</td>\n",
       "      <td>4.75</td>\n",
       "      <td>...</td>\n",
       "      <td>805.00</td>\n",
       "      <td>446.0</td>\n",
       "      <td>1942.000000</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>295.321600</td>\n",
       "      <td>4975.0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>207.00</td>\n",
       "      <td>362.00</td>\n",
       "      <td>3644.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-30</th>\n",
       "      <td>379.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>5665.0</td>\n",
       "      <td>103.00</td>\n",
       "      <td>10848.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>515.00</td>\n",
       "      <td>3482.0</td>\n",
       "      <td>294.73680</td>\n",
       "      <td>5.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1217.00</td>\n",
       "      <td>446.0</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>2059.0</td>\n",
       "      <td>294.042600</td>\n",
       "      <td>4651.0</td>\n",
       "      <td>297.00</td>\n",
       "      <td>362.00</td>\n",
       "      <td>116.00</td>\n",
       "      <td>4559.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-30</th>\n",
       "      <td>380.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6252.0</td>\n",
       "      <td>297.00</td>\n",
       "      <td>9900.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>512.00</td>\n",
       "      <td>3674.0</td>\n",
       "      <td>311.11100</td>\n",
       "      <td>5.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1331.00</td>\n",
       "      <td>424.0</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>2281.0</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>6832.0</td>\n",
       "      <td>291.00</td>\n",
       "      <td>116.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>3704.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-12-31</th>\n",
       "      <td>380.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>291.00</td>\n",
       "      <td>13262.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>534.00</td>\n",
       "      <td>5048.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>5.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1445.00</td>\n",
       "      <td>407.0</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>358.024700</td>\n",
       "      <td>4056.0</td>\n",
       "      <td>157.00</td>\n",
       "      <td>103.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>2849.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-03-31</th>\n",
       "      <td>400.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6286.0</td>\n",
       "      <td>157.00</td>\n",
       "      <td>11018.0</td>\n",
       "      <td>937.0</td>\n",
       "      <td>556.00</td>\n",
       "      <td>3991.0</td>\n",
       "      <td>295.32160</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1242.00</td>\n",
       "      <td>431.0</td>\n",
       "      <td>373.000000</td>\n",
       "      <td>4155.0</td>\n",
       "      <td>287.500000</td>\n",
       "      <td>3567.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>291.00</td>\n",
       "      <td>4116.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-06-30</th>\n",
       "      <td>401.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>6206.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>6963.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>578.00</td>\n",
       "      <td>4148.0</td>\n",
       "      <td>294.04260</td>\n",
       "      <td>6.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>422.0</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>295.967700</td>\n",
       "      <td>4179.0</td>\n",
       "      <td>283.00</td>\n",
       "      <td>291.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>5384.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-09-30</th>\n",
       "      <td>403.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>283.00</td>\n",
       "      <td>5622.0</td>\n",
       "      <td>938.0</td>\n",
       "      <td>805.00</td>\n",
       "      <td>3843.0</td>\n",
       "      <td>294.40000</td>\n",
       "      <td>6.50</td>\n",
       "      <td>...</td>\n",
       "      <td>799.00</td>\n",
       "      <td>411.0</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>295.827000</td>\n",
       "      <td>2361.0</td>\n",
       "      <td>279.00</td>\n",
       "      <td>157.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>4913.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-12-31</th>\n",
       "      <td>401.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>279.00</td>\n",
       "      <td>5363.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>771.00</td>\n",
       "      <td>2668.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1432.00</td>\n",
       "      <td>401.0</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>4143.0</td>\n",
       "      <td>163.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>283.00</td>\n",
       "      <td>4442.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-03-31</th>\n",
       "      <td>401.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>163.00</td>\n",
       "      <td>6163.0</td>\n",
       "      <td>1717.0</td>\n",
       "      <td>737.00</td>\n",
       "      <td>2551.0</td>\n",
       "      <td>287.50000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1480.00</td>\n",
       "      <td>422.0</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>1073.0</td>\n",
       "      <td>294.318200</td>\n",
       "      <td>4270.0</td>\n",
       "      <td>225.00</td>\n",
       "      <td>283.00</td>\n",
       "      <td>279.00</td>\n",
       "      <td>3971.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-06-30</th>\n",
       "      <td>426.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5639.0</td>\n",
       "      <td>225.00</td>\n",
       "      <td>6587.0</td>\n",
       "      <td>1733.0</td>\n",
       "      <td>703.00</td>\n",
       "      <td>2504.0</td>\n",
       "      <td>295.96770</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>955.00</td>\n",
       "      <td>387.0</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>1072.0</td>\n",
       "      <td>294.400000</td>\n",
       "      <td>4191.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>279.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>4218.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-30</th>\n",
       "      <td>420.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>5780.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>6980.0</td>\n",
       "      <td>1836.0</td>\n",
       "      <td>446.00</td>\n",
       "      <td>2464.0</td>\n",
       "      <td>295.82700</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>977.00</td>\n",
       "      <td>395.0</td>\n",
       "      <td>466.000000</td>\n",
       "      <td>878.0</td>\n",
       "      <td>295.700000</td>\n",
       "      <td>3139.0</td>\n",
       "      <td>369.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>4466.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-12-31</th>\n",
       "      <td>421.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>4843.0</td>\n",
       "      <td>369.00</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>463.50</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2061.00</td>\n",
       "      <td>413.0</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>225.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>4713.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-03-31</th>\n",
       "      <td>426.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>6205.0</td>\n",
       "      <td>62.00</td>\n",
       "      <td>6543.0</td>\n",
       "      <td>1845.0</td>\n",
       "      <td>481.00</td>\n",
       "      <td>2683.0</td>\n",
       "      <td>294.31820</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1955.00</td>\n",
       "      <td>383.0</td>\n",
       "      <td>369.000000</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>3657.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>369.00</td>\n",
       "      <td>4961.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30</th>\n",
       "      <td>425.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5855.0</td>\n",
       "      <td>147.00</td>\n",
       "      <td>6174.0</td>\n",
       "      <td>1785.0</td>\n",
       "      <td>534.50</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>294.40000</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1040.00</td>\n",
       "      <td>322.0</td>\n",
       "      <td>459.000000</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>3507.0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>369.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>7030.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-09-30</th>\n",
       "      <td>427.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>5833.0</td>\n",
       "      <td>57.00</td>\n",
       "      <td>6040.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>588.00</td>\n",
       "      <td>2848.0</td>\n",
       "      <td>295.70000</td>\n",
       "      <td>7.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1056.00</td>\n",
       "      <td>309.0</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>948.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>2522.0</td>\n",
       "      <td>310.00</td>\n",
       "      <td>62.00</td>\n",
       "      <td>147.00</td>\n",
       "      <td>6088.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>258.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>6384.0</td>\n",
       "      <td>310.00</td>\n",
       "      <td>5698.0</td>\n",
       "      <td>1539.0</td>\n",
       "      <td>616.50</td>\n",
       "      <td>2853.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2109.00</td>\n",
       "      <td>173.0</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>1563.0</td>\n",
       "      <td>379.487200</td>\n",
       "      <td>3319.0</td>\n",
       "      <td>179.00</td>\n",
       "      <td>147.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>5146.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-03-31</th>\n",
       "      <td>252.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>179.00</td>\n",
       "      <td>4829.0</td>\n",
       "      <td>1740.0</td>\n",
       "      <td>645.00</td>\n",
       "      <td>2892.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1012.00</td>\n",
       "      <td>177.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>3922.0</td>\n",
       "      <td>163.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>310.00</td>\n",
       "      <td>5951.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-06-30</th>\n",
       "      <td>256.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>6265.0</td>\n",
       "      <td>163.00</td>\n",
       "      <td>5213.0</td>\n",
       "      <td>1714.0</td>\n",
       "      <td>622.00</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2161.00</td>\n",
       "      <td>175.0</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>998.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>3880.0</td>\n",
       "      <td>249.00</td>\n",
       "      <td>310.00</td>\n",
       "      <td>179.00</td>\n",
       "      <td>6757.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-30</th>\n",
       "      <td>238.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>6148.0</td>\n",
       "      <td>249.00</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>599.00</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1094.00</td>\n",
       "      <td>159.0</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>919.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>372.00</td>\n",
       "      <td>179.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>6822.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31</th>\n",
       "      <td>237.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>6951.0</td>\n",
       "      <td>372.00</td>\n",
       "      <td>3537.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>613.50</td>\n",
       "      <td>3698.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3141.00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>866.0</td>\n",
       "      <td>358.333300</td>\n",
       "      <td>3819.0</td>\n",
       "      <td>245.00</td>\n",
       "      <td>163.00</td>\n",
       "      <td>249.00</td>\n",
       "      <td>6888.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>237.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6861.0</td>\n",
       "      <td>245.00</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>628.00</td>\n",
       "      <td>3508.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1892.00</td>\n",
       "      <td>139.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>296.039500</td>\n",
       "      <td>4007.0</td>\n",
       "      <td>178.00</td>\n",
       "      <td>249.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>6954.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>236.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>6569.0</td>\n",
       "      <td>178.00</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>641.00</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3064.00</td>\n",
       "      <td>140.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>967.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>4067.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>372.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>7020.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-30</th>\n",
       "      <td>245.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2245.0</td>\n",
       "      <td>1963.0</td>\n",
       "      <td>654.00</td>\n",
       "      <td>3677.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>8.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1853.00</td>\n",
       "      <td>131.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>958.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>2783.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>245.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>6111.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-12-31</th>\n",
       "      <td>243.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>98.00</td>\n",
       "      <td>1047.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>636.50</td>\n",
       "      <td>3612.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>9.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3220.00</td>\n",
       "      <td>115.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>959.0</td>\n",
       "      <td>363.636400</td>\n",
       "      <td>3858.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>178.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>5203.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>243.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6765.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>1885.0</td>\n",
       "      <td>619.00</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>296.03950</td>\n",
       "      <td>10.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1963.00</td>\n",
       "      <td>118.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>966.0</td>\n",
       "      <td>296.062500</td>\n",
       "      <td>3925.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>6468.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>248.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>6307.0</td>\n",
       "      <td>82.00</td>\n",
       "      <td>-692.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>598.00</td>\n",
       "      <td>4073.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>12.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2119.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>300.219300</td>\n",
       "      <td>4820.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>98.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7733.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-30</th>\n",
       "      <td>246.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6007.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>-692.0</td>\n",
       "      <td>1502.0</td>\n",
       "      <td>577.00</td>\n",
       "      <td>4073.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>13.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2119.00</td>\n",
       "      <td>73.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>964.0</td>\n",
       "      <td>315.384600</td>\n",
       "      <td>2702.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>6991.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>244.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>6336.0</td>\n",
       "      <td>94.00</td>\n",
       "      <td>-1515.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>550.50</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>14.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2163.00</td>\n",
       "      <td>78.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>964.0</td>\n",
       "      <td>346.496800</td>\n",
       "      <td>5229.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6249.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>247.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6264.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-212.0</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>524.00</td>\n",
       "      <td>4002.0</td>\n",
       "      <td>296.06250</td>\n",
       "      <td>15.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2098.00</td>\n",
       "      <td>292.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1356.0</td>\n",
       "      <td>349.612100</td>\n",
       "      <td>4804.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>6923.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>217.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>5572.0</td>\n",
       "      <td>61.00</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>610.00</td>\n",
       "      <td>4068.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>16.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2084.00</td>\n",
       "      <td>229.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>4946.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>94.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>7386.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>217.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5840.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>696.00</td>\n",
       "      <td>4003.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>14.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1995.00</td>\n",
       "      <td>294.0</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>1178.0</td>\n",
       "      <td>418.913200</td>\n",
       "      <td>2787.0</td>\n",
       "      <td>81.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>7294.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>217.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>6456.0</td>\n",
       "      <td>81.00</td>\n",
       "      <td>-556.0</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>740.00</td>\n",
       "      <td>3940.0</td>\n",
       "      <td>300.21930</td>\n",
       "      <td>13.50</td>\n",
       "      <td>...</td>\n",
       "      <td>2073.00</td>\n",
       "      <td>303.0</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>600.438600</td>\n",
       "      <td>5073.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>5666.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>218.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6426.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>-775.0</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>784.00</td>\n",
       "      <td>4506.0</td>\n",
       "      <td>296.22560</td>\n",
       "      <td>12.25</td>\n",
       "      <td>...</td>\n",
       "      <td>2716.00</td>\n",
       "      <td>301.0</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>583.984400</td>\n",
       "      <td>4642.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>7441.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-30</th>\n",
       "      <td>218.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5889.0</td>\n",
       "      <td>42.00</td>\n",
       "      <td>-274.0</td>\n",
       "      <td>1273.0</td>\n",
       "      <td>1213.00</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>286.00000</td>\n",
       "      <td>11.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2872.00</td>\n",
       "      <td>290.0</td>\n",
       "      <td>451.000000</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>428.634000</td>\n",
       "      <td>4614.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>6882.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>217.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>1642.00</td>\n",
       "      <td>4064.0</td>\n",
       "      <td>312.14020</td>\n",
       "      <td>10.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2119.00</td>\n",
       "      <td>294.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.0</td>\n",
       "      <td>428.634000</td>\n",
       "      <td>2903.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>7651.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31</th>\n",
       "      <td>216.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>5880.0</td>\n",
       "      <td>51.00</td>\n",
       "      <td>1762.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1151.00</td>\n",
       "      <td>4293.0</td>\n",
       "      <td>600.43860</td>\n",
       "      <td>9.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2111.00</td>\n",
       "      <td>299.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1105.0</td>\n",
       "      <td>428.634000</td>\n",
       "      <td>4173.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>4940.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-31</th>\n",
       "      <td>216.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>6194.0</td>\n",
       "      <td>36.00</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>1126.0</td>\n",
       "      <td>1445.00</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>583.98440</td>\n",
       "      <td>8.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2144.00</td>\n",
       "      <td>311.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>428.634000</td>\n",
       "      <td>4207.0</td>\n",
       "      <td>118.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>5557.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-30</th>\n",
       "      <td>215.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>5835.0</td>\n",
       "      <td>118.00</td>\n",
       "      <td>2921.0</td>\n",
       "      <td>1122.0</td>\n",
       "      <td>946.00</td>\n",
       "      <td>4531.0</td>\n",
       "      <td>428.63400</td>\n",
       "      <td>7.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2117.00</td>\n",
       "      <td>306.0</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>428.634000</td>\n",
       "      <td>4483.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>51.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>6174.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                + Goodwill_lag6  IS_INT_EXPENSE_lag7  IS_OPERATING_EXPN_lag10  \\\n",
       "dates                                                                           \n",
       "2004-12-31                115.0                 87.0                   3167.0   \n",
       "2005-03-31                112.0                 35.0                   3167.0   \n",
       "2005-06-30                107.0                 41.0                   6237.0   \n",
       "2005-09-30                 97.0                 48.0                   6237.0   \n",
       "2005-12-31                 87.0                 25.0                   3022.0   \n",
       "2006-03-31                 95.0                 25.0                   3088.0   \n",
       "2006-06-30                 93.0                 25.0                   7804.0   \n",
       "2006-09-30                 91.0                 79.0                   3032.0   \n",
       "2006-12-31                 87.0                 91.0                   4271.0   \n",
       "2007-03-31                205.0                 91.0                   4755.0   \n",
       "2007-06-30                105.0                 91.0                   4268.0   \n",
       "2007-09-30                218.0                101.0                   4646.0   \n",
       "2007-12-31                218.0                103.0                   4958.0   \n",
       "2008-03-31                208.0                 97.0                   5109.0   \n",
       "2008-06-30                206.0                 96.0                   5239.0   \n",
       "2008-09-30                204.0                 91.0                   5201.0   \n",
       "2008-12-31                204.0                123.0                   5391.0   \n",
       "2009-03-31                204.0                 96.0                   5563.0   \n",
       "2009-06-30                204.0                 93.0                   5499.0   \n",
       "2009-09-30                211.0                112.0                   5380.0   \n",
       "2009-12-31                211.0                 65.0                   5652.0   \n",
       "2010-03-31                377.0                 89.0                   5764.0   \n",
       "2010-06-30                379.0                 98.0                   5665.0   \n",
       "2010-09-30                380.0                101.0                   6252.0   \n",
       "2010-12-31                380.0                 80.0                   6037.0   \n",
       "2011-03-31                400.0                 80.0                   6286.0   \n",
       "2011-06-30                401.0                 80.0                   6206.0   \n",
       "2011-09-30                403.0                 80.0                   5639.0   \n",
       "2011-12-31                401.0                112.0                   5639.0   \n",
       "2012-03-31                401.0                119.0                   5639.0   \n",
       "2012-06-30                426.0                112.0                   5639.0   \n",
       "2012-09-30                420.0                112.0                   5780.0   \n",
       "2012-12-31                421.0                112.0                   4843.0   \n",
       "2013-03-31                426.0                 77.0                   6205.0   \n",
       "2013-06-30                425.0                117.0                   5855.0   \n",
       "2013-09-30                427.0                121.0                   5833.0   \n",
       "2013-12-31                258.0                101.0                   6384.0   \n",
       "2014-03-31                252.0                 73.0                   6400.0   \n",
       "2014-06-30                256.0                115.0                   6265.0   \n",
       "2014-09-30                238.0                111.0                   6148.0   \n",
       "2014-12-31                237.0                117.0                   6951.0   \n",
       "2015-03-31                237.0                123.0                   6861.0   \n",
       "2015-06-30                236.0                119.0                   6569.0   \n",
       "2015-09-30                245.0                122.0                   6240.0   \n",
       "2015-12-31                243.0                114.0                   6445.0   \n",
       "2016-03-31                243.0                109.0                   6765.0   \n",
       "2016-06-30                248.0                114.0                   6307.0   \n",
       "2016-09-30                246.0                109.0                   6007.0   \n",
       "2016-12-31                244.0                107.0                   6336.0   \n",
       "2017-03-31                247.0                 91.0                   6264.0   \n",
       "2017-06-30                217.0                 93.0                   5572.0   \n",
       "2017-09-30                217.0                 81.0                   5840.0   \n",
       "2017-12-31                217.0                 84.0                   6456.0   \n",
       "2018-03-31                218.0                 78.0                   6426.0   \n",
       "2018-06-30                218.0                 75.0                   5889.0   \n",
       "2018-09-30                217.0                 72.0                   5821.0   \n",
       "2018-12-31                216.0                149.0                   5880.0   \n",
       "2019-03-31                216.0                149.0                   6194.0   \n",
       "2019-06-30                215.0                145.0                   5835.0   \n",
       "\n",
       "                + ST Borrowings_lag1  Equity Before Minority Interest_lag8  \\\n",
       "dates                                                                        \n",
       "2004-12-31                    862.00                                4112.0   \n",
       "2005-03-31                    862.00                                4114.5   \n",
       "2005-06-30                    862.00                                4117.0   \n",
       "2005-09-30                    862.00                                3994.0   \n",
       "2005-12-31                    862.00                                3992.0   \n",
       "2006-03-31                    796.25                                4575.0   \n",
       "2006-06-30                    730.50                                5158.0   \n",
       "2006-09-30                    664.75                                4062.0   \n",
       "2006-12-31                    599.00                                4565.0   \n",
       "2007-03-31                    592.75                                5068.0   \n",
       "2007-06-30                    586.50                                5158.0   \n",
       "2007-09-30                    580.25                                5909.0   \n",
       "2007-12-31                    574.00                                6008.0   \n",
       "2008-03-31                    568.75                                6910.0   \n",
       "2008-06-30                    563.50                                6568.0   \n",
       "2008-09-30                    558.25                                7734.0   \n",
       "2008-12-31                    553.00                                8106.0   \n",
       "2009-03-31                    204.00                                7900.0   \n",
       "2009-06-30                    210.00                                7937.0   \n",
       "2009-09-30                    207.00                                8299.0   \n",
       "2009-12-31                    362.00                                8880.0   \n",
       "2010-03-31                    116.00                                9470.0   \n",
       "2010-06-30                    103.00                               10848.0   \n",
       "2010-09-30                    297.00                                9900.0   \n",
       "2010-12-31                    291.00                               13262.0   \n",
       "2011-03-31                    157.00                               11018.0   \n",
       "2011-06-30                    100.00                                6963.0   \n",
       "2011-09-30                    283.00                                5622.0   \n",
       "2011-12-31                    279.00                                5363.0   \n",
       "2012-03-31                    163.00                                6163.0   \n",
       "2012-06-30                    225.00                                6587.0   \n",
       "2012-09-30                     40.00                                6980.0   \n",
       "2012-12-31                    369.00                                6040.0   \n",
       "2013-03-31                     62.00                                6543.0   \n",
       "2013-06-30                    147.00                                6174.0   \n",
       "2013-09-30                     57.00                                6040.0   \n",
       "2013-12-31                    310.00                                5698.0   \n",
       "2014-03-31                    179.00                                4829.0   \n",
       "2014-06-30                    163.00                                5213.0   \n",
       "2014-09-30                    249.00                                4924.0   \n",
       "2014-12-31                    372.00                                3537.0   \n",
       "2015-03-31                    245.00                                2930.0   \n",
       "2015-06-30                    178.00                                3187.0   \n",
       "2015-09-30                      4.00                                2245.0   \n",
       "2015-12-31                     98.00                                1047.0   \n",
       "2016-03-31                     10.00                                1024.0   \n",
       "2016-06-30                     82.00                                -692.0   \n",
       "2016-09-30                      6.00                                -692.0   \n",
       "2016-12-31                     94.00                               -1515.0   \n",
       "2017-03-31                     10.00                                -212.0   \n",
       "2017-06-30                     61.00                                 -28.0   \n",
       "2017-09-30                     10.00                                 225.0   \n",
       "2017-12-31                     81.00                                -556.0   \n",
       "2018-03-31                      6.00                                -775.0   \n",
       "2018-06-30                     42.00                                -274.0   \n",
       "2018-09-30                     15.00                                1284.0   \n",
       "2018-12-31                     51.00                                1762.0   \n",
       "2019-03-31                     36.00                                2029.0   \n",
       "2019-06-30                    118.00                                2921.0   \n",
       "\n",
       "              + LT Investments & Receivables_lag8  \\\n",
       "dates                                               \n",
       "2004-12-31                                  236.0   \n",
       "2005-03-31                                  240.5   \n",
       "2005-06-30                                  245.0   \n",
       "2005-09-30                                  260.0   \n",
       "2005-12-31                                  257.0   \n",
       "2006-03-31                                  349.0   \n",
       "2006-06-30                                  441.0   \n",
       "2006-09-30                                  268.0   \n",
       "2006-12-31                                  289.5   \n",
       "2007-03-31                                  311.0   \n",
       "2007-06-30                                  441.0   \n",
       "2007-09-30                                 1113.0   \n",
       "2007-12-31                                 3729.0   \n",
       "2008-03-31                                 1113.0   \n",
       "2008-06-30                                 1167.0   \n",
       "2008-09-30                                 1182.0   \n",
       "2008-12-31                                 1179.0   \n",
       "2009-03-31                                 1101.0   \n",
       "2009-06-30                                  285.0   \n",
       "2009-09-30                                 1095.0   \n",
       "2009-12-31                                 1085.0   \n",
       "2010-03-31                                 1023.0   \n",
       "2010-06-30                                 1021.0   \n",
       "2010-09-30                                  956.0   \n",
       "2010-12-31                                  949.0   \n",
       "2011-03-31                                  937.0   \n",
       "2011-06-30                                  967.0   \n",
       "2011-09-30                                  938.0   \n",
       "2011-12-31                                  840.0   \n",
       "2012-03-31                                 1717.0   \n",
       "2012-06-30                                 1733.0   \n",
       "2012-09-30                                 1836.0   \n",
       "2012-12-31                                 2015.0   \n",
       "2013-03-31                                 1845.0   \n",
       "2013-06-30                                 1785.0   \n",
       "2013-09-30                                 2015.0   \n",
       "2013-12-31                                 1539.0   \n",
       "2014-03-31                                 1740.0   \n",
       "2014-06-30                                 1714.0   \n",
       "2014-09-30                                 1665.0   \n",
       "2014-12-31                                 1750.0   \n",
       "2015-03-31                                 1988.0   \n",
       "2015-06-30                                 1889.0   \n",
       "2015-09-30                                 1963.0   \n",
       "2015-12-31                                 1926.0   \n",
       "2016-03-31                                 1885.0   \n",
       "2016-06-30                                 1502.0   \n",
       "2016-09-30                                 1502.0   \n",
       "2016-12-31                                 1213.0   \n",
       "2017-03-31                                 1133.0   \n",
       "2017-06-30                                 1163.0   \n",
       "2017-09-30                                 1224.0   \n",
       "2017-12-31                                 1156.0   \n",
       "2018-03-31                                 1198.0   \n",
       "2018-06-30                                 1273.0   \n",
       "2018-09-30                                 1064.0   \n",
       "2018-12-31                                 1043.0   \n",
       "2019-03-31                                 1126.0   \n",
       "2019-06-30                                 1122.0   \n",
       "\n",
       "                + ST Lease Liabilities_lag4    + Other LT Liabilities_lag8  \\\n",
       "dates                                                                        \n",
       "2004-12-31                           444.00                          949.0   \n",
       "2005-03-31                           444.00                          956.0   \n",
       "2005-06-30                           444.00                          963.0   \n",
       "2005-09-30                           444.00                         1095.0   \n",
       "2005-12-31                           444.00                         1460.0   \n",
       "2006-03-31                           444.00                         1825.0   \n",
       "2006-06-30                           444.00                         2190.0   \n",
       "2006-09-30                           444.00                         1039.0   \n",
       "2006-12-31                           523.75                         1632.0   \n",
       "2007-03-31                           603.50                         2225.0   \n",
       "2007-06-30                           683.25                         2190.0   \n",
       "2007-09-30                           763.00                         2310.0   \n",
       "2007-12-31                           736.50                         3882.0   \n",
       "2008-03-31                           710.00                         3409.0   \n",
       "2008-06-30                           683.50                         3183.0   \n",
       "2008-09-30                           657.00                         2709.0   \n",
       "2008-12-31                           623.75                         3122.0   \n",
       "2009-03-31                           590.50                         3048.0   \n",
       "2009-06-30                           557.25                         2717.0   \n",
       "2009-09-30                           524.00                         2679.0   \n",
       "2009-12-31                           521.00                         2727.0   \n",
       "2010-03-31                           518.00                         2991.0   \n",
       "2010-06-30                           515.00                         3482.0   \n",
       "2010-09-30                           512.00                         3674.0   \n",
       "2010-12-31                           534.00                         5048.0   \n",
       "2011-03-31                           556.00                         3991.0   \n",
       "2011-06-30                           578.00                         4148.0   \n",
       "2011-09-30                           805.00                         3843.0   \n",
       "2011-12-31                           771.00                         2668.0   \n",
       "2012-03-31                           737.00                         2551.0   \n",
       "2012-06-30                           703.00                         2504.0   \n",
       "2012-09-30                           446.00                         2464.0   \n",
       "2012-12-31                           463.50                         2848.0   \n",
       "2013-03-31                           481.00                         2683.0   \n",
       "2013-06-30                           534.50                         2787.0   \n",
       "2013-09-30                           588.00                         2848.0   \n",
       "2013-12-31                           616.50                         2853.0   \n",
       "2014-03-31                           645.00                         2892.0   \n",
       "2014-06-30                           622.00                         2988.0   \n",
       "2014-09-30                           599.00                         3102.0   \n",
       "2014-12-31                           613.50                         3698.0   \n",
       "2015-03-31                           628.00                         3508.0   \n",
       "2015-06-30                           641.00                         3595.0   \n",
       "2015-09-30                           654.00                         3677.0   \n",
       "2015-12-31                           636.50                         3612.0   \n",
       "2016-03-31                           619.00                         3576.0   \n",
       "2016-06-30                           598.00                         4073.0   \n",
       "2016-09-30                           577.00                         4073.0   \n",
       "2016-12-31                           550.50                         4196.0   \n",
       "2017-03-31                           524.00                         4002.0   \n",
       "2017-06-30                           610.00                         4068.0   \n",
       "2017-09-30                           696.00                         4003.0   \n",
       "2017-12-31                           740.00                         3940.0   \n",
       "2018-03-31                           784.00                         4506.0   \n",
       "2018-06-30                          1213.00                         4652.0   \n",
       "2018-09-30                          1642.00                         4064.0   \n",
       "2018-12-31                          1151.00                         4293.0   \n",
       "2019-03-31                          1445.00                         4371.0   \n",
       "2019-06-30                           946.00                         4531.0   \n",
       "\n",
       "            Basic Weighted Avg Shares_lag5      + Work In Process_lag7  ...  \\\n",
       "dates                                                                   ...   \n",
       "2004-12-31                       216.41100                       52.00  ...   \n",
       "2005-03-31                       214.75700                       52.00  ...   \n",
       "2005-06-30                       215.83325                       52.00  ...   \n",
       "2005-09-30                       216.90950                       39.75  ...   \n",
       "2005-12-31                       256.83400                       27.50  ...   \n",
       "2006-03-31                       216.95170                       15.25  ...   \n",
       "2006-06-30                       259.45000                        3.00  ...   \n",
       "2006-09-30                       250.33000                       16.00  ...   \n",
       "2006-12-31                       260.00000                       29.00  ...   \n",
       "2007-03-31                       262.30000                       42.00  ...   \n",
       "2007-06-30                       260.46000                       55.00  ...   \n",
       "2007-09-30                       264.86000                       41.75  ...   \n",
       "2007-12-31                       262.60000                       28.50  ...   \n",
       "2008-03-31                       265.80000                       15.25  ...   \n",
       "2008-06-30                       265.23300                        2.00  ...   \n",
       "2008-09-30                       265.45270                        2.50  ...   \n",
       "2008-12-31                       265.86500                        3.00  ...   \n",
       "2009-03-31                       267.51000                        3.50  ...   \n",
       "2009-06-30                       278.52350                        4.00  ...   \n",
       "2009-09-30                       278.78780                        4.25  ...   \n",
       "2009-12-31                       289.58300                        4.50  ...   \n",
       "2010-03-31                       293.72530                        4.75  ...   \n",
       "2010-06-30                       294.73680                        5.00  ...   \n",
       "2010-09-30                       311.11100                        5.25  ...   \n",
       "2010-12-31                       300.21930                        5.50  ...   \n",
       "2011-03-31                       295.32160                        5.75  ...   \n",
       "2011-06-30                       294.04260                        6.00  ...   \n",
       "2011-09-30                       294.40000                        6.50  ...   \n",
       "2011-12-31                       300.21930                        7.00  ...   \n",
       "2012-03-31                       287.50000                        7.50  ...   \n",
       "2012-06-30                       295.96770                        8.00  ...   \n",
       "2012-09-30                       295.82700                        8.00  ...   \n",
       "2012-12-31                       300.21930                        8.00  ...   \n",
       "2013-03-31                       294.31820                        8.00  ...   \n",
       "2013-06-30                       294.40000                        8.00  ...   \n",
       "2013-09-30                       295.70000                        7.75  ...   \n",
       "2013-12-31                       300.21930                        7.50  ...   \n",
       "2014-03-31                       300.21930                        7.25  ...   \n",
       "2014-06-30                       300.21930                        7.00  ...   \n",
       "2014-09-30                       300.21930                        7.00  ...   \n",
       "2014-12-31                       300.21930                        7.00  ...   \n",
       "2015-03-31                       300.21930                        7.00  ...   \n",
       "2015-06-30                       300.21930                        7.00  ...   \n",
       "2015-09-30                       300.21930                        8.25  ...   \n",
       "2015-12-31                       300.21930                        9.50  ...   \n",
       "2016-03-31                       296.03950                       10.75  ...   \n",
       "2016-06-30                       300.21930                       12.00  ...   \n",
       "2016-09-30                       300.21930                       13.00  ...   \n",
       "2016-12-31                       300.21930                       14.00  ...   \n",
       "2017-03-31                       296.06250                       15.00  ...   \n",
       "2017-06-30                       300.21930                       16.00  ...   \n",
       "2017-09-30                       300.21930                       14.75  ...   \n",
       "2017-12-31                       300.21930                       13.50  ...   \n",
       "2018-03-31                       296.22560                       12.25  ...   \n",
       "2018-06-30                       286.00000                       11.00  ...   \n",
       "2018-09-30                       312.14020                       10.00  ...   \n",
       "2018-12-31                       600.43860                        9.00  ...   \n",
       "2019-03-31                       583.98440                        8.00  ...   \n",
       "2019-06-30                       428.63400                        7.00  ...   \n",
       "\n",
       "            Pension Obligations_lag8      + Investments in Affiliates_lag2  \\\n",
       "dates                                                                        \n",
       "2004-12-31                    581.00                                 546.0   \n",
       "2005-03-31                    581.00                                 336.0   \n",
       "2005-06-30                    581.00                                 443.0   \n",
       "2005-09-30                    581.00                                 550.0   \n",
       "2005-12-31                    594.75                                 546.0   \n",
       "2006-03-31                    608.50                                 577.0   \n",
       "2006-06-30                    622.25                                 584.0   \n",
       "2006-09-30                    636.00                                 192.0   \n",
       "2006-12-31                    721.00                                 196.0   \n",
       "2007-03-31                    806.00                                 204.0   \n",
       "2007-06-30                    881.75                                 194.0   \n",
       "2007-09-30                    957.50                                 217.0   \n",
       "2007-12-31                   1033.25                                 244.0   \n",
       "2008-03-31                   1109.00                                 228.0   \n",
       "2008-06-30                   1184.75                                 189.0   \n",
       "2008-09-30                   1260.50                                 177.0   \n",
       "2008-12-31                   1336.25                                 172.0   \n",
       "2009-03-31                   1412.00                                 177.0   \n",
       "2009-06-30                   1403.00                                 179.0   \n",
       "2009-09-30                    990.00                                 197.0   \n",
       "2009-12-31                    897.50                                 142.0   \n",
       "2010-03-31                    805.00                                 446.0   \n",
       "2010-06-30                   1217.00                                 446.0   \n",
       "2010-09-30                   1331.00                                 424.0   \n",
       "2010-12-31                   1445.00                                 407.0   \n",
       "2011-03-31                   1242.00                                 431.0   \n",
       "2011-06-30                   1309.00                                 422.0   \n",
       "2011-09-30                    799.00                                 411.0   \n",
       "2011-12-31                   1432.00                                 401.0   \n",
       "2012-03-31                   1480.00                                 422.0   \n",
       "2012-06-30                    955.00                                 387.0   \n",
       "2012-09-30                    977.00                                 395.0   \n",
       "2012-12-31                   2061.00                                 413.0   \n",
       "2013-03-31                   1955.00                                 383.0   \n",
       "2013-06-30                   1040.00                                 322.0   \n",
       "2013-09-30                   1056.00                                 309.0   \n",
       "2013-12-31                   2109.00                                 173.0   \n",
       "2014-03-31                   1012.00                                 177.0   \n",
       "2014-06-30                   2161.00                                 175.0   \n",
       "2014-09-30                   1094.00                                 159.0   \n",
       "2014-12-31                   3141.00                                 139.0   \n",
       "2015-03-31                   1892.00                                 139.0   \n",
       "2015-06-30                   3064.00                                 140.0   \n",
       "2015-09-30                   1853.00                                 131.0   \n",
       "2015-12-31                   3220.00                                 115.0   \n",
       "2016-03-31                   1963.00                                 118.0   \n",
       "2016-06-30                   2119.00                                  73.0   \n",
       "2016-09-30                   2119.00                                  73.0   \n",
       "2016-12-31                   2163.00                                  78.0   \n",
       "2017-03-31                   2098.00                                 292.0   \n",
       "2017-06-30                   2084.00                                 229.0   \n",
       "2017-09-30                   1995.00                                 294.0   \n",
       "2017-12-31                   2073.00                                 303.0   \n",
       "2018-03-31                   2716.00                                 301.0   \n",
       "2018-06-30                   2872.00                                 290.0   \n",
       "2018-09-30                   2119.00                                 294.0   \n",
       "2018-12-31                   2111.00                                 299.0   \n",
       "2019-03-31                   2144.00                                 311.0   \n",
       "2019-06-30                   2117.00                                 306.0   \n",
       "\n",
       "                + Deferred Tax Liabilities_lag4    + Other ST Assets_lag9  \\\n",
       "dates                                                                       \n",
       "2004-12-31                           313.000000                     728.0   \n",
       "2005-03-31                           313.000000                     728.0   \n",
       "2005-06-30                           313.000000                     696.0   \n",
       "2005-09-30                           313.000000                     664.0   \n",
       "2005-12-31                           313.000000                     703.0   \n",
       "2006-03-31                           313.000000                     748.0   \n",
       "2006-06-30                           313.000000                    1229.5   \n",
       "2006-09-30                           313.000000                    1711.0   \n",
       "2006-12-31                           559.000000                     595.0   \n",
       "2007-03-31                           652.333333                    1327.5   \n",
       "2007-06-30                           745.666667                    2060.0   \n",
       "2007-09-30                           839.000000                    1711.0   \n",
       "2007-12-31                           852.000000                    1629.0   \n",
       "2008-03-31                           865.000000                    2466.0   \n",
       "2008-06-30                           878.000000                    2020.0   \n",
       "2008-09-30                           891.000000                    1479.0   \n",
       "2008-12-31                          1097.000000                    2689.0   \n",
       "2009-03-31                          1203.333333                    3165.0   \n",
       "2009-06-30                          1309.666667                    2503.0   \n",
       "2009-09-30                          1416.000000                    1789.0   \n",
       "2009-12-31                          2913.000000                    1967.0   \n",
       "2010-03-31                          1942.000000                    1192.0   \n",
       "2010-06-30                           438.000000                    2059.0   \n",
       "2010-09-30                           339.000000                    2281.0   \n",
       "2010-12-31                           418.000000                    2388.0   \n",
       "2011-03-31                           373.000000                    4155.0   \n",
       "2011-06-30                           436.000000                    2492.0   \n",
       "2011-09-30                           468.000000                    1122.0   \n",
       "2011-12-31                           466.000000                    1281.0   \n",
       "2012-03-31                           463.000000                    1073.0   \n",
       "2012-06-30                           462.000000                    1072.0   \n",
       "2012-09-30                           466.000000                     878.0   \n",
       "2012-12-31                           428.000000                    1133.0   \n",
       "2013-03-31                           369.000000                    1015.0   \n",
       "2013-06-30                           459.000000                    1273.0   \n",
       "2013-09-30                           431.000000                     948.0   \n",
       "2013-12-31                           239.000000                    1563.0   \n",
       "2014-03-31                            62.000000                    1070.0   \n",
       "2014-06-30                           177.000000                     998.0   \n",
       "2014-09-30                           178.000000                     919.0   \n",
       "2014-12-31                            17.000000                     866.0   \n",
       "2015-03-31                            16.000000                    1006.0   \n",
       "2015-06-30                            14.000000                     967.0   \n",
       "2015-09-30                            14.000000                     958.0   \n",
       "2015-12-31                            13.000000                     959.0   \n",
       "2016-03-31                            13.000000                     966.0   \n",
       "2016-06-30                            12.000000                    1023.0   \n",
       "2016-09-30                            11.000000                     964.0   \n",
       "2016-12-31                            10.000000                     964.0   \n",
       "2017-03-31                             9.000000                    1356.0   \n",
       "2017-06-30                             8.000000                    1212.0   \n",
       "2017-09-30                           -12.000000                    1178.0   \n",
       "2017-12-31                           230.000000                    1142.0   \n",
       "2018-03-31                           307.000000                    1430.0   \n",
       "2018-06-30                           451.000000                    1402.0   \n",
       "2018-09-30                            12.000000                    1365.0   \n",
       "2018-12-31                             8.000000                    1105.0   \n",
       "2019-03-31                            42.000000                    1107.0   \n",
       "2019-06-30                           196.000000                    1023.0   \n",
       "\n",
       "            Diluted Weighted Avg Shares_lag1      + Misc ST Liabilities_lag8  \\\n",
       "dates                                                                          \n",
       "2004-12-31                        256.834000                          2373.0   \n",
       "2005-03-31                        216.951700                          2151.5   \n",
       "2005-06-30                        259.450000                          1930.0   \n",
       "2005-09-30                        287.346700                          1964.0   \n",
       "2005-12-31                        274.823350                          2241.0   \n",
       "2006-03-31                        262.300000                          2815.5   \n",
       "2006-06-30                        260.460000                          3390.0   \n",
       "2006-09-30                        282.261433                          2229.0   \n",
       "2006-12-31                        304.062867                          3046.0   \n",
       "2007-03-31                        325.864300                          3863.0   \n",
       "2007-06-30                        314.394533                          3390.0   \n",
       "2007-09-30                        302.924767                          3768.0   \n",
       "2007-12-31                        291.455000                          4679.0   \n",
       "2008-03-31                        296.183400                          4240.0   \n",
       "2008-06-30                        309.701500                          4059.0   \n",
       "2008-09-30                        307.950000                          4690.0   \n",
       "2008-12-31                        302.174000                          2880.0   \n",
       "2009-03-31                        322.614500                          4653.0   \n",
       "2009-06-30                        311.111000                          4584.0   \n",
       "2009-09-30                        311.111000                          4798.0   \n",
       "2009-12-31                        300.219300                          5236.0   \n",
       "2010-03-31                        295.321600                          4975.0   \n",
       "2010-06-30                        294.042600                          4651.0   \n",
       "2010-09-30                        368.000000                          6832.0   \n",
       "2010-12-31                        358.024700                          4056.0   \n",
       "2011-03-31                        287.500000                          3567.0   \n",
       "2011-06-30                        295.967700                          4179.0   \n",
       "2011-09-30                        295.827000                          2361.0   \n",
       "2011-12-31                        300.219300                          4143.0   \n",
       "2012-03-31                        294.318200                          4270.0   \n",
       "2012-06-30                        294.400000                          4191.0   \n",
       "2012-09-30                        295.700000                          3139.0   \n",
       "2012-12-31                        360.000000                          3326.0   \n",
       "2013-03-31                        300.219300                          3657.0   \n",
       "2013-06-30                        300.219300                          3507.0   \n",
       "2013-09-30                        300.219300                          2522.0   \n",
       "2013-12-31                        379.487200                          3319.0   \n",
       "2014-03-31                        300.219300                          3922.0   \n",
       "2014-06-30                        300.219300                          3880.0   \n",
       "2014-09-30                        300.219300                          3042.0   \n",
       "2014-12-31                        358.333300                          3819.0   \n",
       "2015-03-31                        296.039500                          4007.0   \n",
       "2015-06-30                        300.219300                          4067.0   \n",
       "2015-09-30                        300.219300                          2783.0   \n",
       "2015-12-31                        363.636400                          3858.0   \n",
       "2016-03-31                        296.062500                          3925.0   \n",
       "2016-06-30                        300.219300                          4820.0   \n",
       "2016-09-30                        315.384600                          2702.0   \n",
       "2016-12-31                        346.496800                          5229.0   \n",
       "2017-03-31                        349.612100                          4804.0   \n",
       "2017-06-30                        286.000000                          4946.0   \n",
       "2017-09-30                        418.913200                          2787.0   \n",
       "2017-12-31                        600.438600                          5073.0   \n",
       "2018-03-31                        583.984400                          4642.0   \n",
       "2018-06-30                        428.634000                          4614.0   \n",
       "2018-09-30                        428.634000                          2903.0   \n",
       "2018-12-31                        428.634000                          4173.0   \n",
       "2019-03-31                        428.634000                          4207.0   \n",
       "2019-06-30                        428.634000                          4483.0   \n",
       "\n",
       "                + ST Borrowings      + ST Borrowings_lag3  \\\n",
       "dates                                                       \n",
       "2004-12-31               862.00                    862.00   \n",
       "2005-03-31               862.00                    862.00   \n",
       "2005-06-30               862.00                    862.00   \n",
       "2005-09-30               862.00                    862.00   \n",
       "2005-12-31               796.25                    862.00   \n",
       "2006-03-31               730.50                    862.00   \n",
       "2006-06-30               664.75                    862.00   \n",
       "2006-09-30               599.00                    796.25   \n",
       "2006-12-31               592.75                    730.50   \n",
       "2007-03-31               586.50                    664.75   \n",
       "2007-06-30               580.25                    599.00   \n",
       "2007-09-30               574.00                    592.75   \n",
       "2007-12-31               568.75                    586.50   \n",
       "2008-03-31               563.50                    580.25   \n",
       "2008-06-30               558.25                    574.00   \n",
       "2008-09-30               553.00                    568.75   \n",
       "2008-12-31               204.00                    563.50   \n",
       "2009-03-31               210.00                    558.25   \n",
       "2009-06-30               207.00                    553.00   \n",
       "2009-09-30               362.00                    204.00   \n",
       "2009-12-31               116.00                    210.00   \n",
       "2010-03-31               103.00                    207.00   \n",
       "2010-06-30               297.00                    362.00   \n",
       "2010-09-30               291.00                    116.00   \n",
       "2010-12-31               157.00                    103.00   \n",
       "2011-03-31               100.00                    297.00   \n",
       "2011-06-30               283.00                    291.00   \n",
       "2011-09-30               279.00                    157.00   \n",
       "2011-12-31               163.00                    100.00   \n",
       "2012-03-31               225.00                    283.00   \n",
       "2012-06-30                40.00                    279.00   \n",
       "2012-09-30               369.00                    163.00   \n",
       "2012-12-31                62.00                    225.00   \n",
       "2013-03-31               147.00                     40.00   \n",
       "2013-06-30                57.00                    369.00   \n",
       "2013-09-30               310.00                     62.00   \n",
       "2013-12-31               179.00                    147.00   \n",
       "2014-03-31               163.00                     57.00   \n",
       "2014-06-30               249.00                    310.00   \n",
       "2014-09-30               372.00                    179.00   \n",
       "2014-12-31               245.00                    163.00   \n",
       "2015-03-31               178.00                    249.00   \n",
       "2015-06-30                 4.00                    372.00   \n",
       "2015-09-30                98.00                    245.00   \n",
       "2015-12-31                10.00                    178.00   \n",
       "2016-03-31                82.00                      4.00   \n",
       "2016-06-30                 6.00                     98.00   \n",
       "2016-09-30                94.00                     10.00   \n",
       "2016-12-31                10.00                     82.00   \n",
       "2017-03-31                61.00                      6.00   \n",
       "2017-06-30                10.00                     94.00   \n",
       "2017-09-30                81.00                     10.00   \n",
       "2017-12-31                 6.00                     61.00   \n",
       "2018-03-31                42.00                     10.00   \n",
       "2018-06-30                15.00                     81.00   \n",
       "2018-09-30                51.00                      6.00   \n",
       "2018-12-31                36.00                     42.00   \n",
       "2019-03-31               118.00                     15.00   \n",
       "2019-06-30                16.00                     51.00   \n",
       "\n",
       "                + ST Borrowings_lag2  \\\n",
       "dates                                  \n",
       "2004-12-31                    862.00   \n",
       "2005-03-31                    862.00   \n",
       "2005-06-30                    862.00   \n",
       "2005-09-30                    862.00   \n",
       "2005-12-31                    862.00   \n",
       "2006-03-31                    862.00   \n",
       "2006-06-30                    796.25   \n",
       "2006-09-30                    730.50   \n",
       "2006-12-31                    664.75   \n",
       "2007-03-31                    599.00   \n",
       "2007-06-30                    592.75   \n",
       "2007-09-30                    586.50   \n",
       "2007-12-31                    580.25   \n",
       "2008-03-31                    574.00   \n",
       "2008-06-30                    568.75   \n",
       "2008-09-30                    563.50   \n",
       "2008-12-31                    558.25   \n",
       "2009-03-31                    553.00   \n",
       "2009-06-30                    204.00   \n",
       "2009-09-30                    210.00   \n",
       "2009-12-31                    207.00   \n",
       "2010-03-31                    362.00   \n",
       "2010-06-30                    116.00   \n",
       "2010-09-30                    103.00   \n",
       "2010-12-31                    297.00   \n",
       "2011-03-31                    291.00   \n",
       "2011-06-30                    157.00   \n",
       "2011-09-30                    100.00   \n",
       "2011-12-31                    283.00   \n",
       "2012-03-31                    279.00   \n",
       "2012-06-30                    163.00   \n",
       "2012-09-30                    225.00   \n",
       "2012-12-31                     40.00   \n",
       "2013-03-31                    369.00   \n",
       "2013-06-30                     62.00   \n",
       "2013-09-30                    147.00   \n",
       "2013-12-31                     57.00   \n",
       "2014-03-31                    310.00   \n",
       "2014-06-30                    179.00   \n",
       "2014-09-30                    163.00   \n",
       "2014-12-31                    249.00   \n",
       "2015-03-31                    372.00   \n",
       "2015-06-30                    245.00   \n",
       "2015-09-30                    178.00   \n",
       "2015-12-31                      4.00   \n",
       "2016-03-31                     98.00   \n",
       "2016-06-30                     10.00   \n",
       "2016-09-30                     82.00   \n",
       "2016-12-31                      6.00   \n",
       "2017-03-31                     94.00   \n",
       "2017-06-30                     10.00   \n",
       "2017-09-30                     61.00   \n",
       "2017-12-31                     10.00   \n",
       "2018-03-31                     81.00   \n",
       "2018-06-30                      6.00   \n",
       "2018-09-30                     42.00   \n",
       "2018-12-31                     15.00   \n",
       "2019-03-31                     51.00   \n",
       "2019-06-30                     36.00   \n",
       "\n",
       "            Future Minimum Operating Lease Obligations_lag7  \n",
       "dates                                                        \n",
       "2004-12-31                                          2359.00  \n",
       "2005-03-31                                          2359.00  \n",
       "2005-06-30                                          2359.00  \n",
       "2005-09-30                                          2341.00  \n",
       "2005-12-31                                          2323.00  \n",
       "2006-03-31                                          2305.00  \n",
       "2006-06-30                                          2287.00  \n",
       "2006-09-30                                          2733.00  \n",
       "2006-12-31                                          3179.00  \n",
       "2007-03-31                                          3558.50  \n",
       "2007-06-30                                          3938.00  \n",
       "2007-09-30                                          3949.25  \n",
       "2007-12-31                                          3960.50  \n",
       "2008-03-31                                          3971.75  \n",
       "2008-06-30                                          3983.00  \n",
       "2008-09-30                                          3995.00  \n",
       "2008-12-31                                          4007.00  \n",
       "2009-03-31                                          4019.00  \n",
       "2009-06-30                                          4031.00  \n",
       "2009-09-30                                          3380.00  \n",
       "2009-12-31                                          2729.00  \n",
       "2010-03-31                                          3644.00  \n",
       "2010-06-30                                          4559.00  \n",
       "2010-09-30                                          3704.00  \n",
       "2010-12-31                                          2849.00  \n",
       "2011-03-31                                          4116.50  \n",
       "2011-06-30                                          5384.00  \n",
       "2011-09-30                                          4913.00  \n",
       "2011-12-31                                          4442.00  \n",
       "2012-03-31                                          3971.00  \n",
       "2012-06-30                                          4218.50  \n",
       "2012-09-30                                          4466.00  \n",
       "2012-12-31                                          4713.50  \n",
       "2013-03-31                                          4961.00  \n",
       "2013-06-30                                          7030.00  \n",
       "2013-09-30                                          6088.00  \n",
       "2013-12-31                                          5146.00  \n",
       "2014-03-31                                          5951.50  \n",
       "2014-06-30                                          6757.00  \n",
       "2014-09-30                                          6822.75  \n",
       "2014-12-31                                          6888.50  \n",
       "2015-03-31                                          6954.25  \n",
       "2015-06-30                                          7020.00  \n",
       "2015-09-30                                          6111.50  \n",
       "2015-12-31                                          5203.00  \n",
       "2016-03-31                                          6468.00  \n",
       "2016-06-30                                          7733.00  \n",
       "2016-09-30                                          6991.00  \n",
       "2016-12-31                                          6249.00  \n",
       "2017-03-31                                          6923.00  \n",
       "2017-06-30                                          7386.00  \n",
       "2017-09-30                                          7294.00  \n",
       "2017-12-31                                          5666.00  \n",
       "2018-03-31                                          7441.00  \n",
       "2018-06-30                                          6882.00  \n",
       "2018-09-30                                          7651.00  \n",
       "2018-12-31                                          4940.00  \n",
       "2019-03-31                                          5557.00  \n",
       "2019-06-30                                          6174.00  \n",
       "\n",
       "[59 rows x 26 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor    \n",
    "\n",
    "def calculate_vif_(X, thresh=100):\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "    print('Remaining variables:')\n",
    "    print(X.columns[variables])\n",
    "    return X[cols[variables]]\n",
    "\n",
    "calculate_vif_(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 101) (35, 101) (24, 101)\n"
     ]
    }
   ],
   "source": [
    "# Import the statsmodels.api library with the alias sm\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to the features\n",
    "linear_features = sm.add_constant(features)\n",
    "\n",
    "# Create a size for the training set that is 85% of the total number of samples\n",
    "train_size = int(0.60 * features.shape[0])\n",
    "train_features = X = linear_features[:train_size]\n",
    "train_targets  = Y = targets[:train_size]\n",
    "test_features  = x = linear_features[train_size:]\n",
    "test_targets   = y = targets[train_size:]\n",
    "\n",
    "print(linear_features.shape, train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9461444220528674\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [34, 24]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-473-142b92267ddc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Look at the R^2 scores on train and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[1;32m--> 331\u001b[1;33m                         multioutput='variance_weighted')\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    535\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [34, 24]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create the random forest model and fit to the training data\n",
    "rfr = RandomForestRegressor(n_estimators=400)\n",
    "rfr.fit(train_features, train_targets)\n",
    "\n",
    "# Look at the R^2 scores on train and test\n",
    "print(rfr.score(X, Y))\n",
    "print(rfr.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exrtract features importance with built-in function of random forest regressor\n",
    "features_importances = rfr.feature_importances_\n",
    "\n",
    "# Sort the index that will be our reference for the positino of each index regarding there importances\n",
    "sorted_index = np.argsort(features_importances)[::-1][:20]\n",
    "\n",
    "# Create the corresponding labels to importances position\n",
    "features_count = range(len(sorted_index))\n",
    "labels = np.array(linear_features.columns.to_list())[sorted_index] \n",
    "\n",
    "mpl.rcParams['figure.figsize'] = 20 , 5\n",
    "map_importance(rfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's play with parameter tuning using gridsearch cross validation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [69, 41]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-436-6d1d42026a77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mrfr_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-436-6d1d42026a77>\u001b[0m in \u001b[0;36mrfr_model\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     12\u001b[0m         cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [69, 41]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, cross_val_predict\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def rfr_model(X, Y):\n",
    "    # Perform Grid-Search\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(2,5),\n",
    "            'n_estimators': (10, 50, 100, 200, 400, 600)},\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "    \n",
    "    grid_result = gsc.fit(X, Y)\n",
    "    best_params = grid_result.best_params_\n",
    "    \n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"],                               random_state=False, verbose=False)\n",
    "    # Perform K-Fold CV\n",
    "    scores = cross_val_score(rfr, X, Y, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    return scores\n",
    "\n",
    "rfr_model(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 33]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-392-9920e2c45915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \"\"\"\n\u001b[1;32m--> 225\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 33]"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(rfr, x, y.values.ravel(), cv=10, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 33]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-393-74c0e346b935>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \"\"\"\n\u001b[1;32m--> 763\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 33]"
     ]
    }
   ],
   "source": [
    "predictions = cross_val_predict(rfr, x, y.values.ravel(), cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 33]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-394-2eef955966fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Score of model out-of-sample:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mvizualize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-394-2eef955966fb>\u001b[0m in \u001b[0;36mvizualize_model\u001b[1;34m(model, test_targets)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvizualize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \"\"\"\n\u001b[1;32m--> 763\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 33]"
     ]
    }
   ],
   "source": [
    "def vizualize_model(model, test_targets):\n",
    "    predictions = cross_val_predict(model, x, y.values.ravel(), cv=10)\n",
    "    scores = cross_val_score(model, x, y.values.ravel(), cv=10, scoring='neg_mean_absolute_error')\n",
    "    y_variables = y.values.tolist()\n",
    "    \n",
    "    plt.plot(predictions, 'g', y_variables, 'r')\n",
    "    labels = ['predictions using Random Forest model', y_names]\n",
    "    plt.legend(labels)\n",
    "    \n",
    "    #Print results & comments\n",
    "    print('Mean Y: ', np.mean(y_variables).round(4))\n",
    "    print('Mean predictions: ', np.mean(predictions).round(4))\n",
    "    print('Score of model in sample:', model.score(X, Y).round(4))\n",
    "    print('Score of model out-of-sample:',model.score(x, y).round(4))\n",
    "\n",
    "vizualize_model(rfr, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gradient Boosting Regressor:__\n",
    "\n",
    "https://campus.datacamp.com/courses/machine-learning-for-finance-in-python/machine-learning-tree-methods?ex=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [61, 36]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-395-f0cbf55ab9a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [61, 36]"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=GradientBoostingRegressor(),\n",
    "    param_grid={\n",
    "        'max_depth': range(2,4),\n",
    "        'n_estimators': (200, 400, 600),#, 200, 400, 600),\n",
    "        'learning_rate': (0.2, 0.1, 0.05),#0.04, 0.03, 0.02, 0.01, 0.005),\n",
    "        'subsample': (0.3, 0.4, 0.5),#,0.6, 0.7),\n",
    "        'min_samples_split': (5, 4, 3, 2),#\n",
    "        'random_state': (42, 80),#\n",
    "        'loss': ('ls', 'huber', 'quantile', 'lad')},\n",
    "    cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
    "\n",
    "grid_result = gsc.fit(X, Y)\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "gbr = GradientBoostingRegressor(max_depth         = best_params[\"max_depth\"],\n",
    "                                n_estimators      = best_params[\"n_estimators\"],\n",
    "                                learning_rate     = best_params[\"learning_rate\"],\n",
    "                                subsample         = best_params[\"subsample\"],\n",
    "                                min_samples_split = best_params[\"min_samples_split\"],\n",
    "                                random_state      = best_params[\"random_state\"],\n",
    "                                loss              = best_params[\"loss\"],\n",
    "                                verbose=False)\n",
    "\n",
    "scores = cross_val_score(gbr, X, y, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Perform K-Fold CV\n",
    "gbr.fit(X,Y)\n",
    "\n",
    "print(gbr.score(X, Y))\n",
    "print(gbr.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.08297763, 0.08995838, 0.09235249, ..., 0.32532973, 0.38197842,\n",
       "        0.43581872]),\n",
       " 'std_fit_time': array([0.00837988, 0.00521637, 0.00173941, ..., 0.01037233, 0.01654509,\n",
       "        0.00328324]),\n",
       " 'mean_score_time': array([0.00139537, 0.0011971 , 0.00119729, ..., 0.00159645, 0.00179567,\n",
       "        0.0009974 ]),\n",
       " 'std_score_time': array([0.00048733, 0.00039911, 0.00039878, ..., 0.00048852, 0.00074614,\n",
       "        0.00089207]),\n",
       " 'param_learning_rate': masked_array(data=[0.2, 0.2, 0.2, ..., 0.05, 0.05, 0.05],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_loss': masked_array(data=['ls', 'ls', 'ls', ..., 'lad', 'lad', 'lad'],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[2, 2, 2, ..., 3, 3, 3],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[5, 5, 5, ..., 2, 2, 2],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[200, 200, 200, ..., 600, 600, 600],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_random_state': masked_array(data=[42, 42, 42, ..., 80, 80, 80],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.3, 0.4, 0.5, ..., 0.3, 0.4, 0.5],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.2,\n",
       "   'loss': 'lad',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'ls',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'huber',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 4,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 600,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 200,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.3},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.4},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 42,\n",
       "   'subsample': 0.5},\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'quantile',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 400,\n",
       "   'random_state': 80,\n",
       "   'subsample': 0.3},\n",
       "  ...],\n",
       " 'split0_test_score': array([-2701253.40502295, -3953651.71480261, -3270442.58910964, ...,\n",
       "        -3495280.03307184, -3602341.50679391, -3428773.31089534]),\n",
       " 'split1_test_score': array([-762347.4777637 , -812255.97085835, -972007.66471503, ...,\n",
       "         -88514.68813454,  -63556.84275136,  -63992.34486265]),\n",
       " 'split2_test_score': array([-126937.25784809, -392075.66108494, -127678.4211018 , ...,\n",
       "        -247794.44583398, -427293.43741813, -244039.95474669]),\n",
       " 'split3_test_score': array([-617104.13996089, -649788.98925956, -818928.90798348, ...,\n",
       "        -562503.10974353, -432975.09474158, -500422.57285399]),\n",
       " 'split4_test_score': array([-521591.99472165, -705280.0659073 , -892559.34008981, ...,\n",
       "        -646568.08125465, -650202.15047663, -706811.47213844]),\n",
       " 'mean_test_score': array([ -988661.64896491, -1367270.02268548, -1266423.85300262, ...,\n",
       "        -1068794.21700927, -1097885.21376212, -1048319.28182615]),\n",
       " 'std_test_score': array([ 931779.09169105, 1378411.6639731 , 1103568.57352646, ...,\n",
       "        1302411.02998478, 1341160.26144649, 1280812.60030633]),\n",
       " 'rank_test_score': array([ 105, 1274, 1063, ...,  318,  436,  242]),\n",
       " 'split0_train_score': array([-1.22561222e+01, -1.48572509e-02, -1.79831194e-05, ...,\n",
       "        -3.67419437e+03, -7.74686757e+02, -4.90958138e+02]),\n",
       " 'split1_train_score': array([-4.07625984e+01, -1.47984850e+00, -2.29277619e-03, ...,\n",
       "        -1.48561694e+05, -1.50629898e+05, -2.56781501e+04]),\n",
       " 'split2_train_score': array([-6.76162390e+01, -2.81075663e+00, -1.93926008e-01, ...,\n",
       "        -1.74817739e+05, -7.33316280e+04, -1.98817303e+04]),\n",
       " 'split3_train_score': array([-1.40491851e+02, -8.27926543e-01, -1.00685765e-01, ...,\n",
       "        -1.53869826e+05, -5.68210409e+04, -3.99636666e+04]),\n",
       " 'split4_train_score': array([-1.14391676e+02, -1.28417620e-01, -1.13509603e-02, ...,\n",
       "        -2.54218958e+05, -7.21158236e+04, -4.51797972e+04]),\n",
       " 'mean_train_score': array([-7.51036972e+01, -1.05236131e+00, -6.16546984e-02, ...,\n",
       "        -1.47028482e+05, -7.07346154e+04, -2.62388605e+04]),\n",
       " 'std_train_score': array([4.69134238e+01, 1.02519822e+00, 7.59901467e-02, ...,\n",
       "        8.10699049e+04, 4.79163595e+04, 1.58165190e+04])}"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [61, 36]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-397-d1ae655d5f7f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     tol=0.001)\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mgbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m         \u001b[1;31m# Check input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [61, 36]"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(\n",
    "    loss='ls',\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=400,\n",
    "    subsample=0.6,\n",
    "    criterion='friedman_mse',\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=4,\n",
    "    min_weight_fraction_leaf=0.,\n",
    "    max_depth=3,\n",
    "    min_impurity_decrease=0.1,\n",
    "    min_impurity_split=None,\n",
    "    init=None,\n",
    "    random_state=60,\n",
    "    max_features=20,\n",
    "    alpha=0.8,\n",
    "    verbose=0,\n",
    "    max_leaf_nodes=None,\n",
    "    warm_start=False,\n",
    "    presort='auto',\n",
    "    validation_fraction=0.01,\n",
    "    n_iter_no_change=None,\n",
    "    tol=0.001)\n",
    "\n",
    "gbr.fit(X,Y)\n",
    "print(gbr.score(X, Y))\n",
    "print(gbr.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_importance(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [25, 33]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-399-23586f45e93a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvizualize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-394-2eef955966fb>\u001b[0m in \u001b[0;36mvizualize_model\u001b[1;34m(model, test_targets)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvizualize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     \"\"\"\n\u001b[1;32m--> 763\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lucas\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 235\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [25, 33]"
     ]
    }
   ],
   "source": [
    "vizualize_model(gbr, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
